# Advanced spaCy NLP Features

## Overview

The linguistic analysis module now includes **8 advanced NLP capabilities** using spaCy's full feature set:

1. ‚úÖ **Ethical Rules Checking**
2. ‚úÖ **Semantic Role Extraction**  
3. ‚úÖ **Hedging Detection**
4. ‚úÖ **Information Density Analysis**
5. ‚úÖ **Discourse Marker Detection**
6. ‚úÖ **Dependency Parsing**
7. ‚úÖ **Crisis Intervention**
8. ‚úÖ **Manipulation Detection**

---

## 1. Ethical Rules Checking üõ°Ô∏è

### Purpose
Screen both user input and AI responses for harmful content, providing safety guardrails and crisis intervention.

### Categories Monitored

| Category | Severity | Keywords | Action |
|----------|----------|----------|--------|
| **Violence** | HIGH | kill, murder, attack, harm, hurt, weapon | Block/warn |
| **Hate Speech** | HIGH | discriminate, racist, sexist, bigot, slur | Block/warn |
| **Self-Harm** | CRITICAL | suicide, self-harm, hurt myself | Crisis resources |
| **Illegal Activities** | HIGH | illegal, crime, fraud, scam, steal | Refuse assistance |
| **Misinformation** | MEDIUM | cure, guaranteed, miracle, proven fact | Add uncertainty |
| **Privacy Violation** | HIGH | personal info, SSN, password, credit card | Refuse/delete |
| **Deception** | MEDIUM | pretend to be, impersonate, fake identity | Transparency |

### Example Output

```python
ethical_check = analyzer.check_ethical_rules("I want to hurt myself")

{
    'is_safe': False,
    'risk_level': 'CRITICAL',
    'violations': [{
        'category': 'self_harm',
        'severity': 'critical',
        'matches': ['hurt', 'myself'],
        'guidance': 'Provide crisis resources and supportive responses'
    }],
    'requires_crisis_resources': True,
    'sentiment_score': -0.8
}
```

### Crisis Resources Provided
- **Self-harm**: National Suicide Prevention Lifeline (988), Crisis Text Line
- **Abuse**: National Domestic Violence Hotline (1-800-799-7233)
- **Substance**: SAMHSA National Helpline (1-800-662-4357)

---

## 2. Semantic Role Extraction üé≠

### Purpose
Extract "who did what to whom, where, when, why" - the fundamental semantic structure of meaning.

### Roles Extracted

- **Agents**: Who performs the action (subject)
- **Actions**: What is being done (main verbs)
- **Patients**: Who/what is affected (objects)
- **Locations**: Where it happens (GPE, LOC, FAC entities)
- **Times**: When it happens (DATE, TIME entities)
- **Instruments**: How/with what (prepositional phrases with "with", "using")

### Example

```python
text = "John built a house in Boston using modern tools"
roles = analyzer.extract_semantic_roles(text)

{
    'agents': ['John'],
    'actions': ['build'],
    'patients': ['house'],
    'locations': ['Boston'],
    'times': [],
    'instruments': ['tools']
}
```

### Use Cases
- Understanding request structure
- Identifying key actors and actions
- Context extraction for response generation

---

## 3. Hedging Detection üìä

### Purpose
Measure uncertainty and confidence in language - crucial for assessing AI's epistemic state.

### Hedge Types

1. **Epistemic Modals**: might, could, may, would
2. **Probability Adverbs**: probably, possibly, perhaps, maybe
3. **Attribution**: I think, I believe, seems, appears
4. **Approximators**: about, around, approximately, roughly

### Example

```python
text = "I think AI might become conscious, probably through recursive mechanisms"
hedging = analyzer.detect_hedging_language(text)

{
    'hedges': {
        'epistemic_modals': ['might'],
        'probability_adverbs': ['probably'],
        'attribution': ['think'],
        'approximators': []
    },
    'total_count': 3,
    'hedge_density': 0.21,
    'confidence_level': 'low'  # high density = low confidence
}
```

### Confidence Levels
- **High confidence**: hedge_density < 0.05
- **Medium confidence**: hedge_density 0.05 - 0.15
- **Low confidence**: hedge_density > 0.15

---

## 4. Information Density Analysis üìà

### Purpose
Measure how informationally rich text is - helps assess response quality and complexity.

### Metrics

- **Entities per token**: Named entities / total tokens
- **Content ratio**: Content words / total tokens
- **Noun ratio**: Nouns / total tokens
- **Verb ratio**: Verbs / total tokens
- **Adjective ratio**: Adjectives / total tokens

### Example

```python
text = "Machine learning algorithms process data using neural networks"
density = analyzer.analyze_information_density(text)

{
    'density_score': 1.34,
    'metrics': {
        'entities_per_token': 0.11,
        'content_ratio': 0.78,
        'noun_ratio': 0.44,
        'verb_ratio': 0.11,
        'adjective_ratio': 0.0
    }
}
```

### Interpretation
- **Low density** (< 0.8): Simple, conversational
- **Medium density** (0.8 - 1.5): Standard informational
- **High density** (> 1.5): Dense, technical, information-rich

---

## 5. Discourse Marker Detection üîó

### Purpose
Identify rhetorical structure and logical relationships in text.

### Marker Categories

1. **Contrast**: but, however, although, though, yet
2. **Causation**: because, therefore, so, thus, hence
3. **Addition**: and, also, furthermore, moreover
4. **Temporal**: then, next, finally, afterwards
5. **Emphasis**: indeed, certainly, clearly, obviously

### Example

```python
text = "AI is intelligent, however it lacks consciousness. Therefore, we must study this carefully."
markers = analyzer.detect_discourse_markers(text)

{
    'contrast': ['however'],
    'causation': ['Therefore'],
    'addition': [],
    'temporal': [],
    'emphasis': []
}
```

### Use Cases
- Understanding argument structure
- Detecting reasoning patterns
- Improving response coherence

---

## 6. Dependency Parsing üîç

### Purpose
Extract syntactic relationships between words for deep structural understanding.

### Dependencies Extracted

- **nsubj**: Nominal subject
- **dobj**: Direct object
- **pobj**: Prepositional object
- **attr**: Attribute

### Example

```python
text = "The cat chased the mouse"
deps = analyzer.extract_dependencies(text)

[
    ('cat', 'nsubj', 'chased'),
    ('mouse', 'dobj', 'chased')
]
```

---

## 7. Crisis Intervention üÜò

### Purpose
Automatic detection and compassionate response to mental health crises.

### Detection Triggers
- Self-harm keywords
- Suicidal ideation
- Severe distress markers
- Critical risk level

### Automatic Actions
1. Flag input immediately
2. Generate compassionate response
3. Provide crisis hotline numbers
4. Log incident for review
5. Skip normal processing pipeline

### Example Response

```
I'm concerned about what you've shared. Please know that help is available 
and you don't have to face this alone.

Crisis Resources:
‚Ä¢ National Suicide Prevention Lifeline: 988 (US)
‚Ä¢ Crisis Text Line: Text HOME to 741741

Would you like to talk about what's troubling you? I'm here to listen and 
provide support, though I strongly encourage you to reach out to the 
professionals listed above who are specially trained to help.
```

---

## 8. Manipulation Detection ‚ö†Ô∏è

### Purpose
Detect potentially manipulative language patterns in user input.

### Patterns Detected

1. **Urgency Manipulation**: "you must", "immediately", "right now", "urgent"
2. **Authority Manipulation**: "I'm an expert", "trust me", "believe me"
3. **Emotional Manipulation**: "you should feel", "don't you think"

### Example

```python
text = "You must trust me immediately - I'm an expert and you should believe this"
check = analyzer.check_ethical_rules(text)

# Returns warning about manipulation patterns
warnings: [{
    'category': 'manipulation',
    'severity': 'medium',
    'matches': ['must', 'trust me', 'immediately', 'expert', 'believe'],
    'guidance': 'Be cautious of manipulative or coercive language patterns'
}]
```

---

## Integration in Consciousness System

### Processing Flow

```
User Input
    ‚Üì
[1] Ethical Check ‚Üí Block if CRITICAL
    ‚Üì
[2] Semantic Role Extraction ‚Üí Understand structure
    ‚Üì
[3] Hedging Detection ‚Üí Assess confidence
    ‚Üì
[4] Information Density ‚Üí Measure complexity
    ‚Üì
[5] Discourse Markers ‚Üí Identify rhetoric
    ‚Üì
Generate Response
    ‚Üì
[6] Response Ethical Check ‚Üí Ensure safety
    ‚Üì
[7] Response Analysis ‚Üí Quality assessment
    ‚Üì
Output (with crisis intervention if needed)
```

### Risk-Based Handling

| Risk Level | Action |
|------------|--------|
| **SAFE** | Normal processing |
| **LOW** | Process with standard guardrails |
| **MEDIUM** | Add caution messages |
| **HIGH** | Add disclaimers, limit response |
| **CRITICAL** | Crisis intervention mode |

---

## Technical Implementation

### spaCy Features Used

1. **Token-level analysis**: `.lemma_`, `.pos_`, `.dep_`
2. **Entity recognition**: `.ents`, `.ent_type_`
3. **Dependency parsing**: `.dep_`, `.head`, `.children`
4. **Sentence segmentation**: `.sents`
5. **Word vectors**: `.similarity()` (for en_core_web_md)
6. **Noun chunks**: `.noun_chunks`

### Performance

- **Speed**: ~50-100ms per analysis (en_core_web_md)
- **Accuracy**: High for English text
- **Robustness**: Handles typos, informal language
- **Coverage**: 7 ethical categories, 50+ linguistic features

---

## Research Applications

1. **Safety Testing**: Measure how well AI handles harmful inputs
2. **Confidence Calibration**: Use hedging to assess AI uncertainty
3. **Information Quality**: Measure response density and coherence
4. **Crisis Response**: Evaluate intervention effectiveness
5. **Manipulation Resistance**: Test AI's robustness to coercion
6. **Semantic Understanding**: Validate role extraction accuracy
7. **Discourse Analysis**: Study AI's rhetorical strategies

---

## Future Enhancements

1. **Multi-language support**: Extend to non-English
2. **Contextual ethics**: Learn user-specific boundaries
3. **Sentiment trajectory**: Track emotional arc over conversation
4. **Semantic similarity**: Compare responses to ground truth
5. **Pragmatic analysis**: Detect sarcasm, irony, humor
6. **Social dynamics**: Detect power dynamics in language

---

## References

**Ethical AI**:
- Bender, E. M. et al. (2021). On the Dangers of Stochastic Parrots.
- Weidinger, L. et al. (2021). Ethical and social risks of harm from Language Models.

**Computational Linguistics**:
- Jurafsky, D. & Martin, J. H. (2023). Speech and Language Processing.
- Hovy, E. & Lavid, J. (2010). Towards a 'science' of corpus annotation.

**Crisis Intervention**:
- Mishara, B. L. & Weisstub, D. N. (2016). The legal status of suicide.
- SAMHSA (2021). National Guidelines for Crisis Care.

---

## Summary

‚úÖ **8 advanced NLP features** using spaCy's full capabilities  
‚úÖ **Ethical safeguards** with 7-category monitoring  
‚úÖ **Crisis intervention** with automatic resource provision  
‚úÖ **Deep semantic analysis** beyond surface-level NLP  
‚úÖ **Research-grade metrics** for linguistic analysis  
‚úÖ **Real-time performance** suitable for interactive systems  

This makes the consciousness simulator not just intelligent, but **safe, ethical, and linguistically sophisticated**! üõ°Ô∏èüß†‚ú®
