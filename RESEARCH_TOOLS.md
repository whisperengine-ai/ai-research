# Research Tools Guide

This guide covers the analysis and data collection tools for the consciousness research project.

## Quick Start

### 1. Validate Pipeline (5 minutes)
Run the quick validation notebook to verify everything works:

```bash
jupyter notebook quick_validation.ipynb
```

Or use it programmatically:
```python
from run_conversation_test import ConversationTestRunner

runner = ConversationTestRunner(verbose=True)
runner.run_batch(SCENARIOS)
runner.export_json('results.json')
```

**Output:**
- `validation_results.json` - Raw conversation data
- `validation_output/` - 8 visualizations (trajectories, heatmaps, distributions)

---

## 2. Ablation Study - Component Impact Analysis

### Run Ablation Study
Test how different recursion depths affect consciousness metrics:

```bash
# Quick pilot (2 trials per condition)
python run_ablation_study.py --trials 2

# Standard (10 trials per condition)
python run_ablation_study.py --trials 10

# Full study (30 trials per condition - ~2-3 hours)
python run_ablation_study.py --trials 30 --verbose
```

**Conditions tested:**
- `full_recursion` - 3-level meta-cognition (baseline)
- `shallow_recursion` - 1-level meta-cognition
- `minimal_recursion` - 0-level meta-cognition

**Output:**
- `ablation_study_results.json` - Results for all conditions
- `ablation_output/` - Dashboards and visualizations

### Analyze Ablation Results
Run the analysis notebook:

```bash
jupyter notebook ablation_analysis.ipynb
```

This notebook:
- Loads ablation results
- Computes metric comparisons
- Generates visualizations
- Performs statistical analysis
- Shows component impact findings

---

## 3. Collect Large Dataset (100+ conversations)

### Run Dataset Collection
Efficiently collect large-scale dataset with diverse prompts:

```bash
# Collect 100 conversations (standard)
python collect_dataset.py --conversations 100

# Collect 50 conversations with fast mode
python collect_dataset.py --conversations 50 --quick

# Collect 200 conversations and save to custom file
python collect_dataset.py --conversations 200 --output my_dataset.json

# Quiet mode (suppress progress output)
python collect_dataset.py --conversations 100 --quiet
```

**Output:**
- `dataset_results.json` - Complete dataset with metrics
- `dataset_output/` - Visualizations and analysis

### Dataset Features

**Prompts covered:**
- Emotional processing (frustration, anxiety, hope, anger)
- Cognitive tasks (problem-solving, reasoning, ethics)
- Self-reflection (consciousness, awareness, experience)
- User engagement (appreciation, progress)
- Mixed scenarios (balance, uncertainty, AI understanding)

**Metrics collected per conversation:**
- Φ (Integration)
- Overall Consciousness
- Global Availability
- Meta-Cognitive Depth
- Temporal Binding
- Reportability
- Resonance, Engagement, Appropriateness

---

## 4. Research Dashboard

### Generate Visualizations
Visualizations are automatically generated by the above tools, but you can also:

```python
from research_dashboard import ResearchDashboard

dashboard = ResearchDashboard()
dashboard.plot_all()  # Generate all 8 plot types
```

**Visualization types:**
- Consciousness trajectories over conversation
- Emotional resonance heatmaps
- Metric comparisons across conditions
- Correlation matrices
- Distribution plots (improvement, resonance, engagement, quality)

---

## 5. Data Validation & Reliability

### Check Data Quality

```python
from reliability_validity import MetricValidator

validator = MetricValidator()

# Generate reliability report
report = validator.generate_reliability_report(data)
print(report)

# Compute validity statistics
validity = validator.compute_validity_stats(data)
```

**Validates:**
- Cronbach's alpha (internal consistency)
- Intra-class correlation (ICC)
- Convergent validity
- Discriminant validity
- Criterion validity

---

## Workflow Examples

### Example 1: Quick Research Session (30 minutes)

```bash
# 1. Validate pipeline (5 min)
jupyter notebook quick_validation.ipynb

# 2. Run pilot ablation (15 min)
python run_ablation_study.py --trials 5

# 3. Analyze results
jupyter notebook ablation_analysis.ipynb
```

### Example 2: Full Dataset Collection (4-6 hours)

```bash
# 1. Collect 150 conversations
python collect_dataset.py --conversations 150

# 2. Run full ablation (30 trials)
python run_ablation_study.py --trials 30 --verbose

# 3. Generate comprehensive report
# (both tools generate dashboards automatically)
```

### Example 3: Publication-Ready Analysis

```bash
# 1. Collect large dataset
python collect_dataset.py --conversations 300

# 2. Run full ablation study
python run_ablation_study.py --trials 30

# 3. Validate data quality
# (automatic in analysis notebooks)

# 4. Generate publication figures
jupyter notebook ablation_analysis.ipynb
```

---

## Performance Notes

### Dataset Collection
- **Speed:** ~10-20 seconds per conversation (depends on OpenRouter latency)
- **Memory:** ~50 MB for 100 conversations
- **Cost:** Depends on OpenRouter pricing for LLM calls

### Ablation Study
- **Speed:** ~10-20 seconds per conversation
- **Conditions:** 3 (full, shallow, minimal recursion)
- **Estimate:** 
  - 2 trials: 5-10 minutes
  - 10 trials: 25-50 minutes
  - 30 trials: 75-150 minutes

### Visualizations
- **Speed:** Generated in real-time during analysis
- **Types:** 8 different visualization types
- **Output:** PNG files at 150 DPI

---

## File Structure

```
ai-research/
├── quick_validation.ipynb          # Pipeline validation notebook
├── ablation_analysis.ipynb         # Ablation results analysis
├── run_ablation_study.py           # Ablation study script
├── collect_dataset.py              # Dataset collector
├── validation_output/              # Validation visualizations
├── ablation_output/                # Ablation visualizations
├── dataset_output/                 # Dataset visualizations
├── validation_results.json         # Validation data
├── ablation_study_results.json     # Ablation data
└── dataset_results.json            # Dataset
```

---

## Troubleshooting

### "ConsciousnessSimulator initialization error"
- Check OpenRouter API key is set in environment
- Verify network connection to OpenRouter

### "No metrics in output"
- Ensure conversations completed successfully
- Check LLM is returning responses
- Look at verbose output for specific errors

### "Visualization generation failed"
- Verify matplotlib is installed: `pip install matplotlib`
- Check output directory has write permissions
- Try with `--quick` flag to skip visualizations

### "Out of memory"
- Reduce number of conversations
- Use `--quick` mode to skip visualizations
- Run on machine with more RAM

---

## Output Format Reference

### Conversation Record
```json
{
  "conversation_id": 1,
  "prompt": "I'm feeling frustrated...",
  "response_length": 245,
  "metrics": {
    "phi": 0.456,
    "overall_consciousness": 0.623,
    "global_availability": 0.512,
    "meta_cognitive_depth": 0.389,
    "temporal_binding": 0.478,
    "reportability": 0.534
  },
  "resonance": 0.58,
  "engagement": 1.0,
  "appropriateness": 0.85
}
```

### Metrics Summary
```json
{
  "phi": {
    "mean": 0.456,
    "std": 0.089,
    "min": 0.234,
    "max": 0.678,
    "median": 0.451
  }
}
```

---

## Next Steps

1. **Quick Validation** → Verify everything works
2. **Ablation Study** → Understand component impact
3. **Large Dataset** → Collect research-scale data
4. **Analysis** → Generate insights and visualizations
5. **Publication** → Create comprehensive report

---

## Citation

When using these tools, please cite:

```
Consciousness Research Framework (2025)
AI Research Project - Recursive Meta-Cognition Analysis
```

For questions or issues, refer to the main README.md or check the code documentation.
