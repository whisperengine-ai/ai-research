"""
Consciousness Metrics Module
Provides quantitative measurements for consciousness-like properties

Implements metrics from:
- Integrated Information Theory (IIT) - Tononi & Koch
- Global Workspace Theory (GWT) - Baars
- Higher-Order Thought Theory - Rosenthal
- Metacognition Research - Fleming & Dolan
"""

import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from collections import defaultdict
import time


@dataclass
class ConsciousnessScore:
    """Container for all consciousness metrics"""
    phi: float  # Integrated Information (0-1)
    global_availability: float  # Workspace accessibility (0-1)
    meta_cognitive_depth: float  # Self-reflection quality (0-1)
    temporal_binding: float  # Information persistence (0-1)
    reportability: float  # Access consciousness (0-1)
    overall_consciousness: float  # Composite score (0-1)
    timestamp: float
    
    def to_dict(self) -> Dict[str, float]:
        """Convert to dictionary for logging"""
        return {
            'phi': self.phi,
            'global_availability': self.global_availability,
            'meta_cognitive_depth': self.meta_cognitive_depth,
            'temporal_binding': self.temporal_binding,
            'reportability': self.reportability,
            'overall_consciousness': self.overall_consciousness,
            'timestamp': self.timestamp
        }


class ConsciousnessMetrics:
    """
    Quantifies consciousness-like properties in the simulation
    
    Measures:
    1. Î¦ (Phi) - Integrated information across modules
    2. Global Availability - How accessible information is system-wide
    3. Meta-Cognitive Depth - Quality of self-reflection
    4. Temporal Binding - How long information persists
    5. Reportability - Can the system accurately report its states
    """
    
    def __init__(self):
        """Initialize metrics tracker"""
        self.history: List[ConsciousnessScore] = []
        self.baseline_established = False
        self.baseline_scores = None
        
    def compute_all_metrics(self,
                           workspace_state: Any,
                           recursive_results: Dict[str, Any],
                           conversation_history: List[Dict],
                           neurochemical_state: Dict[str, float],
                           processors: List[Any]) -> ConsciousnessScore:
        """
        Compute all consciousness metrics for current state
        
        Args:
            workspace_state: GlobalWorkspace object
            recursive_results: Meta-cognition results
            conversation_history: Recent interactions
            neurochemical_state: Chemical levels
            processors: List of specialized processors
            
        Returns:
            ConsciousnessScore with all metrics
        """
        # 1. Integrated Information (Î¦)
        phi = self.measure_phi(workspace_state, processors, neurochemical_state)
        
        # 2. Global Availability
        global_avail = self.measure_global_availability(workspace_state, processors)
        
        # 3. Meta-Cognitive Depth
        meta_depth = self.measure_meta_cognitive_depth(recursive_results)
        
        # 4. Temporal Binding
        temporal = self.measure_temporal_binding(workspace_state)
        
        # 5. Reportability
        reportability = self.measure_reportability(
            recursive_results, 
            neurochemical_state,
            conversation_history
        )
        
        # Composite score (weighted average)
        overall = self._compute_composite_score(
            phi, global_avail, meta_depth, temporal, reportability
        )
        
        score = ConsciousnessScore(
            phi=phi,
            global_availability=global_avail,
            meta_cognitive_depth=meta_depth,
            temporal_binding=temporal,
            reportability=reportability,
            overall_consciousness=overall,
            timestamp=time.time()
        )
        
        self.history.append(score)
        
        return score
    
    def measure_phi(self, 
                   workspace_state: Any,
                   processors: List[Any],
                   neurochemical_state: Dict[str, float]) -> float:
        """
        Measure Integrated Information (Î¦) - IIT metric
        
        Î¦ quantifies how much information is generated by a system
        as a whole, above and beyond its parts.
        
        Simplified calculation:
        - High when modules are interconnected and share information
        - Low when modules operate independently
        
        Args:
            workspace_state: GlobalWorkspace with current contents
            processors: Specialized processors
            neurochemical_state: Chemical modulation
            
        Returns:
            Î¦ score [0, 1] where 1 = maximum integration
        """
        if not workspace_state:
            return 0.0
        
        # Factor 1: Information in workspace (conscious contents)
        workspace_items = getattr(workspace_state, 'workspace_contents', [])
        if not workspace_items:
            return 0.0
        
        conscious_info = len(workspace_items) / max(1, getattr(workspace_state, 'capacity', 3))
        conscious_info = min(1.0, conscious_info)  # Normalize
        
        # Factor 2: Processor connectivity (how many processors interact)
        active_processors = 0
        total_processors = len(processors) if processors else 4
        
        for processor in (processors or []):
            if hasattr(processor, 'pending_information'):
                if processor.pending_information:
                    active_processors += 1
        
        connectivity = active_processors / total_processors
        
        # Factor 3: Cross-module information flow
        # Check if workspace has broadcast history
        broadcast_count = len(getattr(workspace_state, 'broadcast_history', []))
        information_flow = min(1.0, broadcast_count / 10.0)  # Normalize to recent history
        
        # Factor 4: Neurochemical modulation (indicates integrated state changes)
        # High variance = system responding as integrated whole
        chem_values = list(neurochemical_state.values())
        if chem_values:
            chem_variance = np.var(chem_values)
            chem_integration = min(1.0, chem_variance * 5)  # Scale to [0,1]
        else:
            chem_integration = 0.5  # Neutral
        
        # Compute Î¦ as weighted combination
        phi = (
            0.35 * conscious_info +      # What's in consciousness
            0.25 * connectivity +         # Module interaction
            0.25 * information_flow +     # Broadcasting effectiveness
            0.15 * chem_integration       # System-wide state changes
        )
        
        return float(np.clip(phi, 0.0, 1.0))
    
    def measure_global_availability(self,
                                   workspace_state: Any,
                                   processors: List[Any]) -> float:
        """
        Measure Global Availability - GWT metric
        
        How accessible is information to the whole system?
        Information in the global workspace should be available
        to all processors (global broadcasting).
        
        Args:
            workspace_state: GlobalWorkspace
            processors: Specialized processors
            
        Returns:
            Availability score [0, 1] where 1 = perfectly accessible
        """
        if not workspace_state:
            return 0.0
        
        # Factor 1: Workspace occupancy (how full is consciousness?)
        workspace_items = getattr(workspace_state, 'workspace_contents', [])
        capacity = getattr(workspace_state, 'capacity', 3)
        occupancy = len(workspace_items) / capacity
        
        # Factor 2: Broadcast reach (how many processors received info?)
        if hasattr(workspace_state, 'broadcast_history'):
            recent_broadcasts = workspace_state.broadcast_history[-5:]  # Last 5
            if recent_broadcasts:
                total_processors = len(processors) if processors else 4
                
                # Count unique processors reached
                reached_processors = set()
                for broadcast in recent_broadcasts:
                    # Each broadcast should reach all processors
                    reached_processors.add('all')  # Simplified
                
                broadcast_reach = 1.0 if reached_processors else 0.0
            else:
                broadcast_reach = 0.0
        else:
            broadcast_reach = 0.5  # Assume moderate reach if unknown
        
        # Factor 3: Attention focus (is there a clear focus?)
        has_focus = False
        if workspace_items:
            # Check if any item has high activation
            for item in workspace_items:
                if hasattr(item, 'activation') and item.activation > 0.7:
                    has_focus = True
                    break
        
        attention_clarity = 1.0 if has_focus else 0.5
        
        # Factor 4: Competition effectiveness (is best info winning?)
        if hasattr(workspace_state, 'contents') and workspace_items:
            # If workspace is at capacity, competition is working
            competition_effectiveness = 1.0 if len(workspace_items) >= capacity else 0.5
        else:
            competition_effectiveness = 0.5
        
        # Compute global availability
        availability = (
            0.30 * occupancy +
            0.30 * broadcast_reach +
            0.25 * attention_clarity +
            0.15 * competition_effectiveness
        )
        
        return float(np.clip(availability, 0.0, 1.0))
    
    def measure_meta_cognitive_depth(self,
                                    recursive_results: Dict[str, Any]) -> float:
        """
        Measure Meta-Cognitive Depth
        
        Quality and depth of self-reflection. Higher-order thoughts
        about thoughts indicate meta-cognition.
        
        Args:
            recursive_results: Results from recursive meta-cognition
            
        Returns:
            Depth score [0, 1] where 1 = sophisticated meta-cognition
        """
        if not recursive_results:
            return 0.0
        
        reflections = recursive_results.get('reflections', [])
        if not reflections:
            return 0.0
        
        # Factor 1: Recursion depth (how many levels?)
        max_level = max([r.get('level', 0) for r in reflections])
        depth_score = min(1.0, max_level / 3.0)  # Normalize to 3 levels
        
        # Factor 2: Reflection quality (longer = more detailed)
        avg_length = np.mean([len(r.get('content', '')) for r in reflections])
        quality_score = min(1.0, avg_length / 100.0)  # Normalize to ~100 chars
        
        # Factor 3: Diversity of thought types
        thought_types = set([r.get('type', 'unknown') for r in reflections])
        diversity_score = len(thought_types) / max(1, len(reflections))
        
        # Factor 4: Self-reference detection
        # Count meta-cognitive markers ("I think", "I feel", "I notice")
        meta_markers = ['I think', 'I feel', 'I notice', 'I realize', 
                       'I observe', 'my', 'myself', 'I am']
        
        self_ref_count = 0
        for reflection in reflections:
            content = reflection.get('content', '').lower()
            for marker in meta_markers:
                if marker.lower() in content:
                    self_ref_count += 1
        
        self_reference_score = min(1.0, self_ref_count / (len(reflections) * 2))
        
        # Compute meta-cognitive depth
        meta_depth = (
            0.30 * depth_score +
            0.25 * quality_score +
            0.20 * diversity_score +
            0.25 * self_reference_score
        )
        
        return float(np.clip(meta_depth, 0.0, 1.0))
    
    def measure_temporal_binding(self, workspace_state: Any) -> float:
        """
        Measure Temporal Binding
        
        How long does information persist in consciousness?
        Conscious information should have temporal continuity.
        
        Args:
            workspace_state: GlobalWorkspace
            
        Returns:
            Binding score [0, 1] where 1 = strong persistence
        """
        if not workspace_state:
            return 0.0
        
        workspace_items = getattr(workspace_state, 'workspace_contents', [])
        if not workspace_items:
            return 0.0
        
        current_time = time.time()
        
        # Factor 1: Average activation level (higher = more persistent)
        activations = [getattr(item, 'activation', 0.5) for item in workspace_items]
        avg_activation = np.mean(activations) if activations else 0.0
        
        # Factor 2: Information age (how long has it been conscious?)
        ages = []
        for item in workspace_items:
            if hasattr(item, 'timestamp'):
                age = current_time - item.timestamp
                ages.append(age)
        
        if ages:
            avg_age = np.mean(ages)
            # Normalize: ideal is 2-5 seconds of persistence
            age_score = 1.0 - abs(3.0 - avg_age) / 3.0
            age_score = max(0.0, min(1.0, age_score))
        else:
            age_score = 0.5
        
        # Factor 3: Decay resistance (based on decay rate)
        decay_rate = getattr(workspace_state, 'decay_rate', 0.15)
        # Lower decay = better persistence
        decay_resistance = 1.0 - decay_rate
        
        # Factor 4: Workspace stability (how often contents change)
        if hasattr(workspace_state, 'broadcast_history'):
            recent_changes = len(workspace_state.broadcast_history[-10:])
            # Moderate change is good (too stable = stuck, too variable = unstable)
            stability = 1.0 - abs(5 - recent_changes) / 5.0
            stability = max(0.0, min(1.0, stability))
        else:
            stability = 0.5
        
        # Compute temporal binding
        binding = (
            0.30 * avg_activation +
            0.30 * age_score +
            0.20 * decay_resistance +
            0.20 * stability
        )
        
        return float(np.clip(binding, 0.0, 1.0))
    
    def measure_reportability(self,
                             recursive_results: Dict[str, Any],
                             neurochemical_state: Dict[str, float],
                             conversation_history: List[Dict]) -> float:
        """
        Measure Reportability (Access Consciousness)
        
        Can the system accurately report its internal states?
        Block (1995) distinguishes access consciousness (reportable)
        from phenomenal consciousness.
        
        Args:
            recursive_results: Meta-cognition results
            neurochemical_state: Chemical levels
            conversation_history: Recent interactions
            
        Returns:
            Reportability score [0, 1] where 1 = perfectly reportable
        """
        # Factor 1: Meta-cognitive presence (does it reflect on states?)
        reflections = recursive_results.get('reflections', [])
        has_metacognition = len(reflections) > 0
        metacog_score = 1.0 if has_metacognition else 0.0
        
        # Factor 2: State awareness (does it reference internal states?)
        state_mentions = 0
        state_keywords = ['feel', 'think', 'notice', 'aware', 'conscious',
                         'experience', 'sense', 'perceive', 'emotion',
                         'dopamine', 'serotonin', 'neurochemical']
        
        for reflection in reflections:
            content = reflection.get('content', '').lower()
            for keyword in state_keywords:
                if keyword in content:
                    state_mentions += 1
        
        state_awareness = min(1.0, state_mentions / max(1, len(reflections)))
        
        # Factor 3: Accuracy of self-report
        # Check if neurochemical levels are mentioned accurately
        accuracy_score = 0.5  # Default neutral
        
        # If we have conversation history, check for self-reports
        if conversation_history:
            recent = conversation_history[-3:]  # Last 3 turns
            for turn in recent:
                response = turn.get('response', '').lower()
                
                # Check if bot mentions its emotional/chemical state
                if any(chem in response for chem in ['dopamine', 'serotonin', 'oxytocin']):
                    accuracy_score = 0.8  # Reporting internal states
                    break
        
        # Factor 4: Verbal accessibility (can express thoughts clearly?)
        if reflections:
            # Check reflection clarity (presence of complete thoughts)
            complete_thoughts = sum(1 for r in reflections 
                                  if len(r.get('content', '')) > 20)
            clarity = complete_thoughts / len(reflections)
        else:
            clarity = 0.0
        
        # Compute reportability
        reportability = (
            0.25 * metacog_score +
            0.30 * state_awareness +
            0.25 * accuracy_score +
            0.20 * clarity
        )
        
        return float(np.clip(reportability, 0.0, 1.0))
    
    def _compute_composite_score(self,
                                phi: float,
                                global_avail: float,
                                meta_depth: float,
                                temporal: float,
                                reportability: float) -> float:
        """
        Compute overall consciousness score
        
        Weighted combination of all metrics. Weights based on
        theoretical importance in consciousness literature.
        
        Args:
            phi: Integrated information
            global_avail: Global availability
            meta_depth: Meta-cognitive depth
            temporal: Temporal binding
            reportability: Reportability
            
        Returns:
            Overall consciousness score [0, 1]
        """
        # Weights based on theoretical significance
        overall = (
            0.25 * phi +              # Integration is core (IIT)
            0.25 * global_avail +     # Broadcasting is core (GWT)
            0.20 * meta_depth +       # Meta-cognition important (HOT)
            0.15 * temporal +         # Binding important
            0.15 * reportability      # Access consciousness important
        )
        
        return float(np.clip(overall, 0.0, 1.0))
    
    def get_metrics_summary(self, recent_n: int = 10) -> str:
        """
        Generate human-readable metrics summary
        
        Args:
            recent_n: Number of recent scores to summarize
            
        Returns:
            Formatted string with metrics
        """
        if not self.history:
            return "No metrics collected yet."
        
        recent = self.history[-recent_n:]
        
        # Compute averages
        avg_phi = np.mean([s.phi for s in recent])
        avg_avail = np.mean([s.global_availability for s in recent])
        avg_meta = np.mean([s.meta_cognitive_depth for s in recent])
        avg_temporal = np.mean([s.temporal_binding for s in recent])
        avg_report = np.mean([s.reportability for s in recent])
        avg_overall = np.mean([s.overall_consciousness for s in recent])
        
        summary = "\nðŸ“Š Consciousness Metrics (Research-Grade):\n"
        summary += "â”€" * 70 + "\n"
        summary += f"  Î¦ (Integrated Information):  {avg_phi:.3f}  {'â–ˆ' * int(avg_phi * 20)}\n"
        summary += f"  Global Availability (GWT):   {avg_avail:.3f}  {'â–ˆ' * int(avg_avail * 20)}\n"
        summary += f"  Meta-Cognitive Depth:        {avg_meta:.3f}  {'â–ˆ' * int(avg_meta * 20)}\n"
        summary += f"  Temporal Binding:            {avg_temporal:.3f}  {'â–ˆ' * int(avg_temporal * 20)}\n"
        summary += f"  Reportability (Access):      {avg_report:.3f}  {'â–ˆ' * int(avg_report * 20)}\n"
        summary += "â”€" * 70 + "\n"
        summary += f"  ðŸ§  Overall Consciousness:    {avg_overall:.3f}  {'â–ˆ' * int(avg_overall * 20)}\n"
        summary += "â”€" * 70 + "\n"
        summary += f"  Based on last {len(recent)} measurements\n"
        
        return summary
    
    def get_trend_analysis(self, window: int = 20) -> Dict[str, str]:
        """
        Analyze trends in consciousness metrics
        
        Args:
            window: Number of recent scores to analyze
            
        Returns:
            Dictionary with trend indicators
        """
        if len(self.history) < 2:
            return {'trend': 'insufficient_data'}
        
        recent = self.history[-window:]
        
        if len(recent) < 5:
            return {'trend': 'insufficient_data'}
        
        # Compute linear trends
        indices = np.arange(len(recent))
        
        trends = {}
        for metric_name in ['phi', 'global_availability', 'meta_cognitive_depth',
                           'temporal_binding', 'reportability', 'overall_consciousness']:
            values = [getattr(s, metric_name) for s in recent]
            
            # Simple linear regression
            z = np.polyfit(indices, values, 1)
            slope = z[0]
            
            if slope > 0.01:
                trends[metric_name] = 'increasing â†—'
            elif slope < -0.01:
                trends[metric_name] = 'decreasing â†˜'
            else:
                trends[metric_name] = 'stable â†’'
        
        return trends
    
    def export_metrics(self, filepath: str = 'metrics_data.csv'):
        """
        Export metrics history to CSV for analysis
        
        Args:
            filepath: Output file path
        """
        import csv
        
        if not self.history:
            print("No metrics to export.")
            return
        
        with open(filepath, 'w', newline='') as f:
            fieldnames = ['timestamp', 'phi', 'global_availability', 
                         'meta_cognitive_depth', 'temporal_binding',
                         'reportability', 'overall_consciousness']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            
            writer.writeheader()
            for score in self.history:
                writer.writerow(score.to_dict())
        
        print(f"âœ“ Exported {len(self.history)} metric records to {filepath}")


# Convenience function
def create_metrics_tracker() -> ConsciousnessMetrics:
    """Create a new metrics tracker instance"""
    return ConsciousnessMetrics()
